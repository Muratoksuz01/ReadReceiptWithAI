{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 2016x928 5 receipts, 677.8ms\n",
      "Speed: 40.0ms preprocess, 677.8ms inference, 2.9ms postprocess per image at shape (1, 3, 2016, 928)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLO pose model\n",
    "model = YOLO(r'models\\train2-20250307T113013Z-001\\train2\\weights\\best.pt')\n",
    "\n",
    "# Load the image\n",
    "image_path = r\"receipt_Sample.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Perform inference\n",
    "results = model(image)\n",
    "\n",
    "# Eğer model herhangi bir kutu algıladıysa işle\n",
    "if results[0].boxes is not None and results[0].keypoints is not None:\n",
    "    boxes = results[0].boxes.xyxy.cpu().numpy()  # (Nesne Sayısı, 4) → [x1, y1, x2, y2]\n",
    "    box_confidences = results[0].boxes.conf.cpu().numpy()  # (Nesne Sayısı,) → Kutuların güven skorları\n",
    "    keypoints = results[0].keypoints.xy.cpu().numpy()  # (Nesne Sayısı, Keypoint Sayısı, 2)\n",
    "    keypoint_confidences = results[0].keypoints.conf.cpu().numpy()  # (Nesne Sayısı, Keypoint Sayısı)\n",
    "\n",
    "    # En yüksek güven skoruna sahip kutuyu seç\n",
    "    best_box_index = box_confidences.argmax()\n",
    "    best_box = boxes[best_box_index]  # [x1, y1, x2, y2]\n",
    "\n",
    "    # En iyi kutuya ait keypointleri al\n",
    "    best_keypoints = keypoints[best_box_index]  # (Keypoint Sayısı, 2)\n",
    "    best_keypoint_confidences = keypoint_confidences[best_box_index]  # (Keypoint Sayısı,)\n",
    "\n",
    "    # Kutuyu çiz\n",
    "    x1, y1, x2, y2 = map(int, best_box)\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 3)  # Yeşil kutu\n",
    "\n",
    "    # En iyi 4 keypoint'i seç ve çiz\n",
    "    top_4_indices = best_keypoint_confidences.argsort()[-4:]  # En yüksek 4 güvene sahip noktayı al\n",
    "    for idx in top_4_indices:\n",
    "        x, y = map(int, best_keypoints[idx])\n",
    "        cv2.circle(image, (x, y), 8, (0, 0, 255), -1)  # Kırmızı noktalar\n",
    "\n",
    "# Pencere boyutunu ayarla\n",
    "max_size = 800  # Maksimum genişlik/yükseklik\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "if max(height, width) > max_size:\n",
    "    scale = max_size / max(height, width)\n",
    "    new_size = (int(width * scale), int(height * scale))\n",
    "    image = cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# Show the image with the best box and keypoints\n",
    "cv2.imshow('Best Box & Keypoints', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# segmentasn \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fis_100_jpg.rf.4479da7899ddf514a2cfba9d87b7f832.jpg', 156)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os,cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "# path=\"C:\\\\Users\\\\denem\\\\Desktop\\\\roboflow_156_foot\\\\train\\\\images\\\\\"\n",
    "# path=\"C:\\\\Users\\\\denem\\\\Desktop\\\\realtest\\\\\"\n",
    "path=r\"images/\"\n",
    "# path=\"C:\\\\Users\\\\denem\\\\Desktop\\\\realtest_net\\\\\"\n",
    "files=os.listdir(path)\n",
    "files[0],len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 2016x1152 1 Receipt, 967.8ms\n",
      "Speed: 34.3ms preprocess, 967.8ms inference, 10.5ms postprocess per image at shape (1, 3, 2016, 1152)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# YOLO segmentasyon modelini yükle\n",
    "model = YOLO(r'models\\train-seg\\train\\weights\\best.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Resmi yükle\n",
    "image_path = path+files[7]\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Model ile tahmin yap\n",
    "results = model(image)\n",
    "\n",
    "# Segmentasyon maskesi için bir boş görüntü oluştur\n",
    "mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "\n",
    "# Eğer segmentasyon sonuçları varsa devam et\n",
    "if results[0].masks is not None:\n",
    "    masks = results[0].masks.xy  # Maskelerin kontur noktaları (x, y) formatında\n",
    "\n",
    "    # Her bir maskeyi çiz\n",
    "    for mask_points in masks:\n",
    "        points = np.array(mask_points, dtype=np.int32)\n",
    "        cv2.fillPoly(mask, [points], 255)  # Maskeyi beyaz ile doldur\n",
    "\n",
    "    # Orijinal görüntü ile maskeyi birleştirerek göster\n",
    "    segmented_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Maske görselleştirmesi için renkli hale getir (mavi overlay ekledik)\n",
    "    overlay = cv2.merge([mask, np.zeros_like(mask), np.zeros_like(mask)])\n",
    "    output = cv2.addWeighted(image, 0.7, overlay, 0.3, 0)\n",
    "\n",
    "else:\n",
    "    output = image.copy()  # Eğer mask bulunamazsa orijinal görüntüyü göster\n",
    "\n",
    "# ** Pencere Boyutunu Ayarla **\n",
    "max_size = 800  # Maksimum genişlik/yükseklik\n",
    "height, width = output.shape[:2]\n",
    "\n",
    "if max(height, width) > max_size:\n",
    "    scale = max_size / max(height, width)\n",
    "    new_size = (int(width * scale), int(height * scale))\n",
    "    output = cv2.resize(output, new_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# Sonucu göster\n",
    "cv2.imshow('Segmented Image', output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
